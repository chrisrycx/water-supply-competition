{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Model Prediction - V2\n",
    "Predict seasonal flow volumes using combination of snow pack, antecedent flow models and quantile regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import QuantileRegressor, LinearRegression\n",
    "import datetime\n",
    "from typing import Literal, Tuple\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load SNODAS, antecedent flow, and submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "snodas_data = pd.DataFrame()\n",
    "for year in range(2005,2024):\n",
    "    year_data = pd.read_csv(f'./data/snodas/snodas_swe_{year}.csv', index_col=0, parse_dates=True)\n",
    "    snodas_data = pd.concat([snodas_data, year_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_submission = pd.read_csv('./data/competition/submission_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_flow = pd.read_csv('./data/competition/test_monthly_naturalized_flow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('./data/competition/metadata.csv').set_index('site_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names of the SNODAS data to match the other datasets\n",
    "snodas_data.columns = metadata.index.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle the models\n",
    "with open('./model/snow_models.pkl', 'rb') as f:\n",
    "    snow_models = pickle.load(f)\n",
    "\n",
    "with open('./model/antecedent_flow_models.pkl', 'rb') as f:\n",
    "    antecedent_flow_models = pickle.load(f)\n",
    "\n",
    "with open('./model/total_flow_quantile_models.pkl', 'rb') as f:\n",
    "    total_flow_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess antecedent flow data\n",
    "I visually verifed that the test data is cleaner than the training data and has no nans or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to determine months of antecedent flow. The water year starts in October, so antecedent flow for a given month is every month of the water year before that month.\n",
    "water_year_months = [10,11,12,1,2,3,4,5,6,7,8,9]\n",
    "def antecedent_months(month: int) -> Tuple[int]:\n",
    "    return tuple(water_year_months[:water_year_months.index(month)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.335\n"
     ]
    }
   ],
   "source": [
    "# Create a function for getting total antecedent flow for a given site and month. Return series of years.\n",
    "# In order to keep the same interface, I will include a day parameter. So for example, total flow on 2/15 will be total flow for January.\n",
    "def get_antecedent_flow(site_id: str, day: int, month: int, year: int) -> float:\n",
    "    site_flow_data: pd.DataFrame = monthly_flow.loc[monthly_flow['site_id'] == site_id,:].copy()\n",
    "    site_flow_data['antecedent'] = site_flow_data['month'].apply(lambda x: True if x in antecedent_months(month) else False)\n",
    "\n",
    "    # Calculate total flow where is_runoff is True by site and year\n",
    "    site_flow_totals = site_flow_data[site_flow_data['antecedent']].groupby(['site_id','forecast_year']).sum().reset_index()\n",
    "\n",
    "    site_flow_totals.set_index('forecast_year', inplace=True)\n",
    "    \n",
    "    return site_flow_totals.loc[year,'volume']\n",
    "\n",
    "# Test the function at the pecos_r_nr_pecos\n",
    "print(get_antecedent_flow('pecos_r_nr_pecos', 15, 1,2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify sites that have no antecedent flow data.\n",
    "sites_no_antecedent = [site for site in snodas_data.columns if site not in monthly_flow['site_id'].unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to perform the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_quantile(site:str, prediction_date_str: str, quantile: Literal['0.1','0.5','0.9']):\n",
    "    \"\"\"\n",
    "    Predicts the total seasonal volumn for a given site using the snow and antecedent flow models as input to the total flow model.\n",
    "\n",
    "    Sites without antecedent flow data will use the snow model only.\n",
    "\n",
    "    Any dates that are after the runoff start date use the value for the runoff start date.\n",
    "    \"\"\"\n",
    "    # Convert the prediction date to a datetime object\n",
    "    prediction_date = datetime.datetime.strptime(prediction_date_str, '%Y-%m-%d').date()\n",
    "\n",
    "    # Check if the prediction date is on or after the runoff start date\n",
    "    # If it is, use the runoff start data and don't use the snow or antecedent flow models\n",
    "    is_after_season_start = False\n",
    "    season_start_month = metadata.loc[site,'season_start_month']\n",
    "    if prediction_date.month >= season_start_month:\n",
    "        prediction_date = datetime.date(prediction_date.year, season_start_month, 1)\n",
    "        is_after_season_start = True\n",
    "\n",
    "    # First determine season start SWE\n",
    "    if is_after_season_start:\n",
    "        # Handle missing 2017-04-01 from SNODAS data\n",
    "        if prediction_date == datetime.date(2017,4,1):\n",
    "            prediction_date = datetime.date(2017,4,8)\n",
    "\n",
    "        # Get the snodas data for the site and date and convert to KAF\n",
    "        season_start_swe = snodas_data.loc[prediction_date.strftime('%Y-%m-%d'), site] / 1233.48\n",
    "    else:\n",
    "        # Get the model for the site and date\n",
    "        site_snow_model: LinearRegression = snow_models[site][(prediction_date.month, prediction_date.day)]\n",
    "        current_swe = snodas_data.loc[prediction_date.strftime('%Y-%m-%d'), site]\n",
    "\n",
    "        # Predict season start SWE\n",
    "        season_start_swe = site_snow_model.predict([[current_swe]])[0][0]\n",
    "        season_start_swe = season_start_swe/1233.48 #KAF\n",
    "\n",
    "    # Second determine antecedent flow for sites with antecedent flow data\n",
    "    antecedent_flow = None\n",
    "    if site not in sites_no_antecedent:\n",
    "        if is_after_season_start:\n",
    "            antecedent_flow = get_antecedent_flow(site, prediction_date.day, prediction_date.month, prediction_date.year)\n",
    "        else:\n",
    "            site_antecedent_flow_model: LinearRegression = antecedent_flow_models[site][(prediction_date.month, prediction_date.day)]\n",
    "            current_antecedent_flow = get_antecedent_flow(site, prediction_date.day, prediction_date.month, prediction_date.year)\n",
    "            antecedent_flow = site_antecedent_flow_model.predict([[current_antecedent_flow]])[0][0]\n",
    "\n",
    "    # Finally predict total flow from swe and antecedent flow\n",
    "    total_flow_model: QuantileRegressor = total_flow_models[site][quantile]\n",
    "    if site in sites_no_antecedent:\n",
    "        total_flow = total_flow_model.predict([[season_start_swe]])[0]\n",
    "    else:\n",
    "        total_flow = total_flow_model.predict([[season_start_swe, antecedent_flow]])[0]\n",
    "\n",
    "    return total_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.16835931011733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clmbn\\CRCEAnalytics\\WaterSupplyComp\\.drivendata\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but QuantileRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test = predict_quantile('pecos_r_nr_pecos', '2023-01-01', '0.5')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict quantiles for each site\n",
    "Use the submission format to generate all the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_submission['volume_10'] = model_submission.apply(lambda row: predict_quantile(row['site_id'], row['issue_date'], '0.1'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_submission['volume_50'] = model_submission.apply(lambda row: predict_quantile(row['site_id'], row['issue_date'], '0.5'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_submission['volume_90'] = model_submission.apply(lambda row: predict_quantile(row['site_id'], row['issue_date'], '0.9'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the submission to csv\n",
    "model_submission.to_csv('./data/competition/submissions/quantileV2_submission_122023.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".drivendata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
